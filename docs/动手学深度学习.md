# 动手学深度学习
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202311061034697.png)
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202311061100337.png)  
多层感知机分类的时候如何判断哪一个特征对分类结果影响更大。首先在MLP比较简单的时候, 你可以去检查对某个特征的权重大小。在神经网络比较复杂的时候(包括更复杂的模型), 人们把模型视为一个黑盒而去考虑具体特征对输出有什么贡献, 这一问题对应于深度学习的可解释性这一领域, 具体比较简单的方法有’leave one out’, ‘shap’ 等, 具体可以查看相关资料, 这里简单介绍leave one out的想法
把每个特征一个一个地mask掉, 看输出的改变, 对于mask后导致输出改变更大的特征, 认为它的贡献比较大  
通常来说，权重会初始化为较小的随机值，比如乘以0.01，有助于避免初始值过大或过小导致的梯度爆炸或梯度消失问题。偏置则通常初始化为零值。在神经网络中，权重和偏置通常被设置为requires_grad=True，以便在训练过程中能够对它们进行优化。

0轴求和保留一行，1轴求和保留一列   
交叉熵损失函数。 这可能是深度学习中最常见的损失函数，因为目前分类问题的数量远远超过回归问题的数量。  

概率密度函数就是参数和样本x的多元函数  f(θ,X)二元函数，给定θ时，f(θ,X)描述产生样本X的可能性/概率(在很小的区间里的积分)；给定X时，f(θ,X)描述在X下，分布参数是θ的可能性。 其实就是描述可能性，一个是θ参数的可能性，一个是产生样本X的可能性。  
所谓的似然就是给定X后f的值（因为这时候描述的是θ的可能性，让其最大的θ就是最可能出现的参数值）当前样本来自什么参数的分布的可能性最大。  


平方损失函数就是对theta的极大似然估计
平方损失函数是定义出来的，所谓假设误差服从正态分布仅仅说明了为什么可以这样定义。  
softmax输出是一个向量（对每个样本而言），是各个类的概率分布，训练目标是让该yhat接近分类目标的onehot向量（样本自带的标签）。  
而这样的话我们就只需要保证分类目标的概率最大就行了，再用平方损失函数的话要求就太高了，因此我们引入交叉熵损失函数。当然也要对样本数做平均。本质上就是只算分类目标那个类的-log而已。  


负采样这一技巧其实在别的算法中也有应用，其适用的场景是结果中正例比较少而负例比较多的情形，就比如word2vec，无论是CBOW模式还是skip-gram模型，整个词库词语数量为V，CBOW预测中间词，输出中只有中间词为1，其余词都为0;skip-gram预测周围词，只有周围有限的n个词为1，其余都为0，这两种模式下都是正例数很少，而负例数很多的情形。正是基于这样一种实际情况，负采样的思想就是只取所有正样本和部分负样本，比如按照1比10的比例选取负样本，然后整个预测输出的规模就变小了，这样再去计算softmax的时候计算量就很小了。（预测输出的概率分布中不会有那么多及其接近0的值了）  
3.4.6.1对数似然里面会讲，这**里要反复理解**  

GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB  
搞明白所谓的device号是怎么回事，fede里通过gpu参数来控制使用哪个  
再看看所谓collection是指什么  
改了一下max epoch  
进程stopped之后并不会死掉  

collection就是和isolation相对的不联邦在一起训练。  
transE是completion里面的，fede用它来测试embedding的效果  

本质就是function中的每个f分别对变元中的每个元素逐个求偏导，求导的布局是另外考虑的事情。**先算出结果再去考虑布局。** 分子布局就是分子是没转置的列向量，分母是转置之后的行向量或者矩阵。矩阵变元和矩阵函数都用vec拉成向量形式去解决。
摆放：列优先去求导，行优先去放在结果矩阵里面。即所谓先计算再摆放。       
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202311101033658.png)  
这里如果按先计算的原则的话xtA和Atx是等价的。
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202311101050211.png)
如果这个了然了，矩阵求导也就了然。  
but！神经网络动不动就几百层，你去手写导数是一件很难的事情。  
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202311101057746.png)
这里正向先给出各个中间变量的表示，反向再去用这些表示去求梯度。  
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202311101102873.png)

**深度学习中我们很少用向量函数求导，绝大多数对标量求导**。即便y有些时候是向量通常也会把它转化成标量（例如sum()一下,是向量每个分量的函数，但是求偏导全没了）再去对向量求导。    
具体来说，.detach() 的作用是返回一个新的张量，该张量与原始张量共享相同的底层数据存储，但不再与计算图相连接。（也就是说不再参与链式法则）例子：
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202311101114988.png)
深度学习框架可以自动隐式地构建计算图，因此如果x定义时确定了要算梯度，那么得到y之后调用一个backward函数就可以得到y关于x的梯度。这种自动求导还有一个好处就是可以跨越python控制流得到梯度。一个python函数f(a)通过反向传播也可以获得a的梯度。  

**上午断章在线性回归视频，大概已经完全参透线性回归了，留个尾巴给简要表示**

线性回归一般是要用均方损失和sgd（随机梯度下降），softmax（逻辑回归）则用log似然？看看  
注意最后sgd是对[w,b]进行的更新，也就是说b偏置也要更新。  
注意课程里给出的构建人造数据集的过程，是已知了真实的w和b再通过这个去构建样本特征和标签。而后面还会通过模型将另一组随机初始化的w和b优化成近似真实值的w和b。所谓true值只是为了数据集的构建方便，和最后能对模型训练出的w和b与真实值做一个评估。  
事实上，交叉熵loss原本就是取ground truth类别的预测概率的负对数作为loss，因为真实分布中只有真实类别（ground truth类别，或者就叫正例）的标签为1，其他（负例）全为0。 

负样本打分越高的负样本权重越高，理解成要去着重优化降低其打分。整个损失函数理解成提高正样本打分，降负样本打分