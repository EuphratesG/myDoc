# 频率学派和贝叶斯学派、概率模型和非概率模型、生成式模型和判别式模型


  

---
### 贝叶斯学派和频率学派（MLE、MAP、贝叶斯估计）
**概率是样本空间的公理，频率派和贝叶斯派的区别只是对概率的理解和对模型参数的理解。**   频率派认为概率就是频率的极限，贝叶斯派认为概率是信心的度量。实验数量不是无限的情况下频率派偶发事件影响严重，贝叶斯派可以引入先验。     
**两大学派的求解问题思路主要为：训练（MLE、MAP、贝叶斯估计求解模型参数）、预测（判别或者生成）**。





#### 两大学派和正则的关系
正则化本质上是人类主观添加的规则，用于弥补数据的不完美。  
频率派认为数据应能客观反映现实，因此只关注极大似然估计，而贝叶斯派则认为数据有限且不完美，因此引入先验概率，并通过贝叶斯定理修正为后验概率。这种额外的假设被称为正则。  
频率学派的MLE损失函数加上正则化项后就是MAP的损失函数，殊途同归。**经验风险最小化和结构风险最小化**。期望损失和经验风险/结构风险的区别：一个是损失函数的数学期望一个是损失函数的样本平均数，但P（X，Y）不可知（也就是）

### 监督学习中的生成式模型和判别式模型
直接看b站情书的朴素贝叶斯就是生成模型的典型。朴素贝叶斯训练过程就是在数据集中统计计算概率，朴素在于各个特征互相独立。对p（xy）建模（因为都求出来了）然后自然地由贝叶斯公式得到要求的条件概率。最后取分类类别的时候单纯的概率高的是。   
![](https://cdn.jsdelivr.net/gh/EuphratesG/myPic@main/202501260929882.png)  
**生成式模型到底是怎么生成的找到病因了**，输出不是单个概率值，而是一个概率分布！！！通过这个概率分布去做采样。开始时生成第一个单词，输出第一个单词的概率分布（如 "The": 0.5, "A": 0.3, "It": 0.2）。采样第一个单词：从分布中采样得到 "The"。而判别式模型只能输出一个概率值。 MLM也只是bert训练时做的一个带训练目标的句子分类而已



### **概念辨析：MLE、MAP、生成式模型、判别式模型**

这几个概念分属不同维度，但它们在实际模型训练和预测中相互关联。以下是分层次的解析：

---

### **1. 参数估计方法：MLE vs. MAP**
这两个概念是**参数估计方法**，用于从数据中学习模型参数。

| **方法**   | **核心思想**                                                                 | **公式**                                                                 | **特点**                                                                 |
|------------|-----------------------------------------------------------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------|
| **MLE**    | 最大化**似然函数**，找到最可能生成数据的参数（仅依赖数据本身）。                          | \( \theta_{\text{MLE}} = \arg\max_{\theta} P(D \mid \theta) \)           | 完全依赖数据，可能过拟合（尤其是小数据场景）。                                     |
| **MAP**    | 在MLE基础上引入**先验分布**，找到后验概率最大的参数（结合数据与先验知识）。                   | \( \theta_{\text{MAP}} = \arg\max_{\theta} P(D \mid \theta)P(\theta) \) | 通过先验修正参数估计，更鲁棒（如拉普拉斯平滑）。                                    |

**关系与区别**：  
- MLE是MAP的特例（当先验分布是均匀分布时，MAP退化为MLE）。  
- **实际应用**：  
  - 朴素贝叶斯中的条件概率估计使用MAP（拉普拉斯平滑）。  
  - 逻辑回归的参数估计通常使用MLE（交叉熵损失），但加入L2正则化等价于MAP（高斯先验）。

---

### **2. 模型类型：生成式模型 vs. 判别式模型**
这两个概念是**模型的设计范式**，决定了模型如何建模输入 \( X \) 和输出 \( Y \) 的关系。

| **模型类型**     | **建模目标**                               | **核心能力**                     | **典型例子**                              |
|------------------|------------------------------------------|----------------------------------|------------------------------------------|
| **生成式模型**   | 联合分布 \( P(X, Y) \)                     | 生成新样本、分类、数据补全          | 朴素贝叶斯、隐马尔可夫模型（HMM）、GAN           |
| **判别式模型**   | 条件分布 \( P(Y \mid X) \)                 | 分类、回归、预测                   | 逻辑回归、支持向量机（SVM）、神经网络、线性回归    |

**关系与区别**：  
- **生成式模型**需要显式建模数据的生成过程（如 \( P(X \mid Y) \) 和 \( P(Y) \)），因此计算复杂度更高。  
- **判别式模型**直接关注输入到输出的映射，通常更高效且在小样本任务中表现更好。  

---

### **3. 参数估计方法与模型类型的交叉关系**
生成式模型和判别式模型在训练时，均可使用MLE或MAP进行参数估计。以下是典型组合：

#### **(1) 生成式模型 + MAP**  
- **例子**：朴素贝叶斯（带拉普拉斯平滑）。  
- **过程**：  
  1. 假设先验分布（如Dirichlet先验）。  
  2. 通过最大化后验概率 \( P(\theta \mid D) \) 估计参数（如条件概率 \( P(X_i \mid Y) \)）。  

#### **(2) 生成式模型 + MLE**  
- **例子**：高斯混合模型（GMM）。  
- **过程**：  
  直接最大化似然函数 \( P(D \mid \theta) \)，估计高斯分布的均值和方差。  

#### **(3) 判别式模型 + MLE**  
- **例子**：逻辑回归（无正则化）。  
- **过程**：  
  最大化条件似然 \( P(Y \mid X, \theta) \)，使用交叉熵损失函数。  

#### **(4) 判别式模型 + MAP**  
- **例子**：带L2正则化的逻辑回归。  
- **过程**：  
  最大化后验概率 \( P(\theta \mid D) \)，等价于在损失函数中加入L2正则项（假设参数服从高斯先验）。  

---

### **4. 总结：一张表理清所有关系**
| **维度**          | **生成式模型**                          | **判别式模型**                          |
|-------------------|----------------------------------------|----------------------------------------|
| **核心建模目标**   | \( P(X, Y) \)                          | \( P(Y \mid X) \)                      |
| **能否生成数据**   | 能（如生成图片、文本）                    | 不能                                   |
| **参数估计方法**   | MLE（如GMM）、MAP（如朴素贝叶斯）         | MLE（如逻辑回归）、MAP（如带L2正则化的SVM） |
| **典型任务**       | 生成、分类、聚类                        | 分类、回归、预测                        |

---

### **5. 常见问题解答**
#### **Q1：生成式模型一定比判别式模型强吗？**  
- **不一定**！生成式模型需要更强的假设（如朴素贝叶斯的特征独立性假设），如果假设不成立，性能可能较差。判别式模型通常在小样本或复杂任务中表现更好。

#### **Q2：MAP和贝叶斯估计有什么区别？**  
- **MAP**是点估计（取后验概率最大的参数值），**贝叶斯估计**是积分所有参数可能性（计算后验分布的期望）。贝叶斯估计更全面但计算复杂，MAP是实用折中。

#### **Q3：逻辑回归是生成式还是判别式模型？**  
- **判别式模型**，因为它直接建模 \( P(Y \mid X) \)，不涉及 \( P(X) \) 或 \( P(X \mid Y) \)。

---

### **最终结论**
- **MLE/MAP**是参数估计方法，**生成式/判别式**是模型设计范式，两者是正交的维度。  
- 实际中选择哪种组合，取决于任务需求（是否需要生成数据）、数据量（小数据适合MAP）和模型假设的合理性。





房价预测的线性回归模型属于**判别式模型**。以下是关键分析步骤：

1. **模型目标**：  
   线性回归旨在直接学习输入变量（如房屋面积、位置等）与输出变量（房价）之间的映射关系，即建模条件概率 \( P(Y|X) \)。它关注的是在给定特征 \( X \) 时如何预测目标值 \( Y \)，而非联合分布 \( P(X,Y) \)。

2. **生成式 vs 判别式的核心区别**：  
   - **生成式模型**（如朴素贝叶斯）学习联合分布 \( P(X,Y) \)，可生成新的数据样本（如模拟房屋特征和对应价格）。  
   - **判别式模型**（如逻辑回归、支持向量机）直接建模 \( P(Y|X) \) 或决策边界，仅关注预测输出，不涉及输入数据的生成。

3. **线性回归的数学本质**：  
   假设目标变量 \( Y \) 服从以 \( X \) 的线性组合为均值的高斯分布，通过最大似然估计参数。这种条件概率建模方式（\( Y \) 依赖于 \( X \)）明确属于判别式框架。

4. **误区澄清**：  
   即使模型能预测 \( Y \)，若未对 \( X \) 的分布进行建模（如生成新房屋特征），仍为判别式模型。生成式模型需同时描述 \( X \) 和 \( Y \) 的关系。

**结论**：线性回归通过直接建模条件概率 \( P(Y|X) \) 完成预测任务，属于典型的判别式模型。

### 概率模型和非概率模型
**极大似然估计、最大后验估计、贝叶斯估计，这些都是基于概率似然的，所以一定是概率模型**。生成式模型一定是概率模型，判别式模型可以是概率模型（线性回归的噪声假设）也可以是非概率模型（线性回归直接设fx求）



### 那么损失函数是怎么来的呢？
机器学习领域，注意是机器学习领域，我们要找到输入X和输出Y（标签Y）的关系。而大前提就是XY满足一个联合分布（代表X和Y存在某种机器学习要拟合的目标关系，所以最终结果的XY关系当然不会相互独立）   
频率学派根据最大似然估计，做多次实验，把在该参数下每次实验结果的概率乘起来，因为这是确定的已知结果所以让该概率值最大的参数值就是模型的参数值。  
贝叶斯学派则根据最大后验估计引入先验。随着样本量的增加，后验分布的先验信息影响会减弱，最终后验分布会接近似然函数，即MLE的结果。  

**那么损失函数和这些有什么关系**？**损失函数是标签Y和预测值FX的函数**。损失函数可以是根据朴素逻辑得到的（例如感知机模型，针对误分类点到超平面的距离总和进行建模，该值最小自然模型拟合完毕），也可以是根据最大似然估计的式子截取的和模型参数有关的部分（例如平方误差损失就是回归问题，噪声满足高斯分布的前提下最大似然估计的式子里取和模型参数有关的部分得到的）总而言之损失函数都必须是模型参数的函数，同时优化它可以达到拟合理想模型参数的目的。  



我们可以将GPT的Decoder结构、训练目标（预训练与微调）以及推理生成过程，与联合分布建模的具体例子结合起来，分步骤解释生成式模型如何实现 \( P(X, Y) \) 的学习与生成。以下是详细说明：

---

### **一、GPT的Decoder结构与训练目标**
#### **1. Decoder架构的核心机制**
- **自回归（Autoregressive）**：GPT的Decoder逐词生成文本，每一步只能看到当前词左侧的上下文（通过**Masked Self-Attention**实现）。
- **输入表示**：文本序列被转换为Token Embeddings + Positional Embeddings，输入Decoder层。
- **输出预测**：每个位置输出下一个Token的概率分布（通过Softmax）。

#### **2. 预训练目标：语言建模**
- **任务**：给定前文 \( w_1, w_2, \ldots, w_{t-1} \)，预测下一个词 \( w_t \)。
- **数学形式**：最大化似然函数：
  \[
  \mathcal{L} = \sum_{t=1}^T \log P(w_t | w_1, \ldots, w_{t-1})
  \]
- **本质**：通过逐词预测，模型隐式学习文本序列的联合分布 \( P(X) \)（无监督场景）。

#### **3. 微调目标：任务导向的联合分布建模**
- **任务示例**：情感分析（\( X \)=文本，\( Y \)=标签）。
- **输入格式**：将任务转化为文本生成。例如：
  - 输入序列："这部电影很无聊。情感标签："
  - 目标输出："负面"
- **训练目标**：模型学习联合分布 \( P(X, Y) \)，即同时建模文本 \( X \) 和标签 \( Y \) 的关系。

---

### **二、训练过程：如何建模联合分布 \( P(X, Y) \)？**
#### **案例：情感分析任务**
假设训练数据包含电影评论 \( X \) 和标签 \( Y \)（正面/负面）。

##### **步骤1：数据格式化**
- 将标签 \( Y \) 作为文本的一部分输入模型。例如：
  ```
  输入序列："情感分析：这部电影太棒了！标签："
  目标输出："正面"
  ```
  （通过这种方式，模型将 \( X \) 和 \( Y \) 视为一个整体序列）

##### **步骤2：联合分布的分解**
- 模型的训练目标变为预测标签 \( Y \)（即下一个Token），基于输入文本 \( X \)：
  \[
  P(X, Y) = P(Y | X) \cdot P(X)
  \]
  其中 \( P(X) \) 已在预训练阶段通过语言建模学习。

##### **步骤3：参数更新**
- 模型通过交叉熵损失，学习从 \( X \) 到 \( Y \) 的映射，同时保持对 \( X \) 生成能力（预训练知识的迁移）。

---

### **三、推理过程：如何生成 \( X \) 或 \( Y \)？**
#### **案例1：生成标签 \( Y \)（判别式任务）**
- **输入**："情感分析：这部电影节奏拖沓，毫无新意。标签："
- **生成过程**：
  1. Decoder逐步生成Token，基于上文预测下一个词。
  2. 模型根据预训练和微调学到的联合分布 \( P(X, Y) \)，计算候选词（如“负面”“正面”）的概率。
  3. 选择概率最高的词作为输出（如“负面”）。

#### **案例2：生成文本 \( X \)（生成式任务）**
- **输入**："生成一段负面影评："
- **生成过程**：
  1. Decoder从起始Token开始，逐词生成文本。
  2. 每一步基于已生成的内容（如“服务差，价格高”），预测下一个词（如“，再也不会光顾了。”）。
  3. 生成的文本需符合“负面”标签的语义（隐式调用 \( P(X | Y=\text{负面}) \)）。

---

### **四、联合分布建模的底层实现**
#### **1. 自注意力机制的作用**
- **捕捉长程依赖**：模型通过Self-Attention，识别文本中与标签相关的关键片段。  
  （例如，在情感分析中，关注“无聊”“糟糕”等词）
- **标签与文本的关联**：在微调阶段，标签 \( Y \) 作为输入的一部分，通过注意力权重与文本 \( X \) 建立联系。

#### **2. 概率链式法则的具体化**
假设生成序列为 \( S = [X; Y] = [w_1, w_2, \ldots, w_T] \)，模型通过链式法则建模联合分布：
\[
P(S) = P(w_1) \cdot P(w_2 | w_1) \cdot \ldots \cdot P(w_T | w_1, \ldots, w_{T-1})
\]
- **标签生成**：若 \( Y \) 是序列的最后几个Token（如“标签：负面”），模型需基于前文 \( X \) 计算 \( P(Y | X) \)。
- **文本生成**：若 \( X \) 是序列的后半部分（如“生成负面影评：…”），模型需基于标签 \( Y \) 计算 \( P(X | Y) \)。

#### **3. 生成策略（推理阶段）**
- **贪心搜索（Greedy Search）**：每一步选择概率最高的词，但可能陷入局部最优。
- **束搜索（Beam Search）**：保留多个候选序列，平衡生成质量与多样性。
- **采样（Sampling）**：根据概率分布随机采样，增加生成多样性。

---

### **五、训练与推理的对比**
| **阶段** | **训练（预训练+微调）**                          | **推理（生成）**                              |
|----------|------------------------------------------------|---------------------------------------------|
| **目标** | 最大化文本序列的似然概率，建模 \( P(X) \) 或 \( P(X, Y) \) | 从学习到的分布中采样，生成符合任务需求的序列               |
| **输入** | 完整文本序列（可能包含标签）                          | 部分序列（如Prompt），由模型补全                     |
| **输出** | 计算损失并更新参数                                | 生成Token序列（如标签或文本）                      |
| **关键** | 通过Masked Attention限制仅看到左侧上下文              | 自回归生成，每一步依赖已生成的Token                 |

---

### **六、总结：GPT如何实现联合分布建模**
1. **架构设计**：Decoder的自回归结构天然适合序列生成，逐词预测本质上是建模联合分布 \( P(X) \) 或 \( P(X, Y) \)。
2. **训练目标**：通过语言模型预训练学习 \( P(X) \)，微调阶段将任务转化为序列生成（如 \( X \rightarrow Y \) 或 \( Y \rightarrow X \)），扩展为 \( P(X, Y) \)。
3. **推理灵活性**：  
   - 给定 \( X \) 生成 \( Y \)（如分类任务），本质是计算 \( P(Y | X) \)；  
   - 给定 \( Y \) 生成 \( X \)（如文本生成），本质是计算 \( P(X | Y) \)；  
   - 自由生成 \( (X, Y) \) 对（如数据增强），本质是从 \( P(X, Y) \) 中采样。

**最终答案**：GPT通过自回归Decoder结构、语言模型预训练和任务微调，隐式学习数据与标签的联合分布 \( P(X, Y) \)。在推理时，它通过调整输入提示（Prompt）灵活切换生成方向，既可生成文本 \( X \)（如评论），也可生成标签 \( Y \)（如情感），体现了对联合分布的统一建模能力。


好的！我们通过一个具体的文本生成例子，结合数学公式，说明语言模型如何将联合概率分解为条件概率链，并以GPT为例解释其训练和生成过程。

---

### **例子：生成句子 "我喜欢学习"**
假设模型要生成句子 \( S = \) "我喜欢学习"，对应的词序列为 \( w_1=我, w_2=喜欢, w_3=学习 \)。  
语言模型的目标是建模整个序列的联合概率 \( P(w_1, w_2, w_3) \)，并通过链式法则将其分解为条件概率的乘积。

---

#### **1. 联合概率的链式分解**
根据概率链式法则，联合概率可以分解为：
\[
P(w_1, w_2, w_3) = P(w_1) \cdot P(w_2 | w_1) \cdot P(w_3 | w_1, w_2)
\]
- **第一步**：生成第一个词 \( w_1=我 \) 的概率 \( P(w_1) \)。
- **第二步**：在已生成 \( w_1=我 \) 的条件下，生成第二个词 \( w_2=喜欢 \) 的概率 \( P(w_2 | w_1) \)。
- **第三步**：在已生成 \( w_1=我, w_2=喜欢 \) 的条件下，生成第三个词 \( w_3=学习 \) 的概率 \( P(w_3 | w_1, w_2) \)。

---

#### **2. 条件概率的具体计算（以GPT为例）**
GPT通过自回归机制逐词生成，每一步基于上文预测下一个词。假设模型参数已通过训练学习到以下条件概率（简化示例）：

- **生成第一个词 \( w_1=我 \)**：  
  初始状态下，模型从所有可能的首词中选择，例如：
  \[
  P(w_1=我) = 0.3, \quad P(w_1=你) = 0.2, \quad P(w_1=今天) = 0.1, \quad \ldots
  \]
  最终选择概率最高的 \( w_1=我 \)。

- **生成第二个词 \( w_2=喜欢 \)**：  
  基于上文 \( w_1=我 \)，模型计算：
  \[
  P(w_2=喜欢 | w_1=我) = 0.6, \quad P(w_2=讨厌 | w_1=我) = 0.1, \quad \ldots
  \]
  选择 \( w_2=喜欢 \)。

- **生成第三个词 \( w_3=学习 \)**：  
  基于上文 \( w_1=我, w_2=喜欢 \)，模型计算：
  \[
  P(w_3=学习 | w_1=我, w_2=喜欢) = 0.5, \quad P(w_3=睡觉 | w_1=我, w_2=喜欢) = 0.2, \quad \ldots
  \]
  选择 \( w_3=学习 \)。

最终联合概率为：
\[
P(我, 喜欢, 学习) = 0.3 \times 0.6 \times 0.5 = 0.09
\]

---

### **3. GPT的训练过程：最大化似然估计**
在预训练阶段，GPT通过大量文本学习这些条件概率。例如，给定句子片段 "我 喜欢 _"，模型的目标是最大化下一个词为 "学习" 的概率：
\[
\mathcal{L} = \log P(w_3=学习 | w_1=我, w_2=喜欢)
\]
通过反向传播调整模型参数，使得模型输出的条件概率 \( P(w_3=学习 | w_1=我, w_2=喜欢) \) 尽可能接近实际数据中的分布。

---

- **联合概率分解**：语言模型通过链式法则 \( P(w_1, \ldots, w_T) = \prod_{t=1}^T P(w_t | w_1, \ldots, w_{t-1}) \) 将联合分布转化为条件概率的乘积。







神经网络通过多层感知器的组合叠加解决非线性分类问题的理解可以分为以下几个关键点：

---

### **1. 单层感知器的局限性**
**感知器（Perceptron）**是最简单的神经网络单元，本质是一个线性分类器：
- **数学形式**：\( y = \sigma(w \cdot x + b) \)，其中 \( \sigma \) 是激活函数（如阶跃函数）。
- **能力**：只能解决**线性可分**问题（如AND、OR逻辑门），但无法处理**非线性可分**问题（如XOR异或逻辑）。

**示例**：XOR问题的线性不可分性  
<img src="https://miro.medium.com/v2/resize:fit:1400/1*Tc8UgR_fjI_h0p3y4HvMwA.png" width="300"/>

单层感知器无法找到一条直线将XOR的两类数据分开。

---

### **2. 多层感知器的核心思想**
通过**叠加多个感知器层**（隐藏层），并引入**非线性激活函数**，神经网络可以学习复杂的非线性决策边界。  
- **关键操作**：  
  1. **线性变换**：每层通过权重 \( W \) 和偏置 \( b \) 对输入进行线性组合。  
  2. **非线性激活**：对线性变换的结果应用激活函数（如ReLU、Sigmoid），打破线性限制。  
  3. **逐层传递**：将前一层的输出作为下一层的输入，逐步抽象特征。

**示例**：用两层感知器解决XOR问题  
<img src="https://miro.medium.com/v2/resize:fit:1400/1*3QSFbW4UZv4jq4v6Vyj8TA.png" width="400"/>

- **第一层**：构建两个线性边界，将输入空间划分为多个区域。  
- **第二层**：组合第一层的输出，形成最终的XOR决策边界。

---

### **3. 非线性激活函数的作用**
若没有非线性激活函数，多层感知器等价于单层线性模型。  
**常见激活函数**：  
- **Sigmoid**：\( \sigma(z) = \frac{1}{1+e^{-z}} \)，输出范围(0,1)，适合概率映射。  
- **ReLU**：\( \text{ReLU}(z) = \max(0, z) \)，解决梯度消失问题，加速训练。  
- **Tanh**：\( \tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} \)，输出范围(-1,1)，中心对称。

**数学解释**：  
假设一个两层网络：
\[
y = W_2 \cdot \sigma(W_1 \cdot x + b_1) + b_2
\]
- 若 \( \sigma \) 是线性函数（如恒等函数），则整体仍是线性变换：  
  \[
  y = W_2 \cdot (W_1 \cdot x + b_1) + b_2 = (W_2 W_1) \cdot x + (W_2 b_1 + b_2)
  \]
- **非线性激活函数**使得网络的表达能力指数级增强，能够逼近任意复杂函数（Universal Approximation Theorem）。

---

### **4. 多层组合的直观理解**
神经网络通过逐层抽象特征，将低层特征组合为高层语义：
- **输入层**：原始数据（如像素值）。  
- **隐藏层1**：检测简单模式（如边缘、颜色）。  
- **隐藏层2**：组合简单模式为复杂结构（如纹理、形状）。  
- **输出层**：综合高层特征进行分类（如物体类别）。

**示例**：图像分类  
<img src="https://developers.google.com/static/machine-learning/practical/images/mlcc/feature_hierarchy.png" width="500"/>

- **浅层**：边缘、角点 → **中层**：纹理、部件 → **深层**：物体整体。

---

### **5. 反向传播与参数优化**
多层感知器的训练依赖于**反向传播算法**和**梯度下降**：
1. **前向传播**：计算预测值 \( \hat{y} \) 和损失函数 \( \mathcal{L} \)。  
2. **反向传播**：从输出层到输入层逐层计算梯度 \( \frac{\partial \mathcal{L}}{\partial W} \)。  
3. **参数更新**：通过梯度下降调整权重和偏置，最小化损失。

**数学形式**：  
对于权重 \( W_{ij}^{(l)} \)（第 \( l \) 层第 \( i \) 个神经元到第 \( j \) 个神经元的连接权重）：
\[
W_{ij}^{(l)} \leftarrow W_{ij}^{(l)} - \eta \cdot \frac{\partial \mathcal{L}}{\partial W_{ij}^{(l)}}
\]
其中 \( \eta \) 是学习率。

---

### **6. 神经网络与非线性分类的实例**
**问题**：用神经网络对螺旋形数据进行分类。  
**网络结构**：3层（输入层→隐藏层→输出层），激活函数为ReLU。  
**训练结果**：  
<img src="https://cs231n.github.io/assets/nn1/spiral_net.png" width="400"/>

- **单层网络**：只能拟合线性边界，分类失败。  
- **多层网络**：通过非线性激活和组合，形成复杂决策边界。

---

### **总结**
- **单层感知器的限制**：仅能解决线性可分问题。  
- **多层感知器的突破**：通过叠加隐藏层和非线性激活函数，学习复杂非线性关系。  
- **核心机制**：  
  1. **线性变换**：组合输入特征。  
  2. **非线性激活**：引入表达能力。  
  3. **反向传播**：优化模型参数。  
- **直观理解**：逐层抽象特征，从简单模式到复杂语义，最终解决非线性分类问题。