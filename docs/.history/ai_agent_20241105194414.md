# RAG 和使用工具在智能体（AI agents）解决大模型幻觉（hallucination）方面的异同

## RAG（Retrieval-Augmented Generation）

### 基本概念：
RAG结合了检索和生成两种方法。首先从外部知识库中检索相关信息，然后用这些信息作为上下文生成回答。

### 优点：
- **增强信息准确性**：通过检索外部信息，模型可以获取最新和更准确的数据，从而减少生成内容中的错误或虚构信息。
- **上下文丰富**：提供更多的背景信息，有助于生成更符合实际的响应。

### 适用场景：
- 适合需要大量事实支持的任务，如问答系统和信息检索。

## 使用工具

### 基本概念：
使用工具是指智能体在执行任务时调用外部工具或API（如数据库查询、计算器、网络搜索等）来获取所需信息。

### 优点：
- **实时数据访问**：可以直接从工具中获取实时信息，确保信息的时效性和准确性。
- **灵活性**：能够执行复杂的操作，如数据处理、计算或图形生成，直接响应用户请求。

### 适用场景：
- 适合需要动态响应或处理具体任务的场景，如编程助手、数据分析等。

## 异同点

### 共同点：
- 两者都旨在提高生成内容的准确性，减少幻觉。
- 都依赖外部信息源来增强模型的能力。

### 不同点：
- **信息获取方式**：RAG依赖于静态知识库的检索，而使用工具则可以实时访问动态数据或功能。
- **复杂性**：RAG相对简单，主要依赖检索；使用工具可以涉及更复杂的操作和交互。
- **场景适应性**：RAG更适合知识密集型任务，而使用工具则更灵活，适应各种实际需求。

总的来说，两者各有优势，结合使用时可以进一步提升智能体的性能，减少生成幻觉的可能性。

---

# 大语言模型与LLM的未来

我很看好LLM，大部分公司是想让LLM做100%的事情，这是不可能的。LLM只能解决80%-90%的事情，剩下的10%-20%如果想要靠LLM去解决，需要花上几倍甚至几十倍的代价。起码未来几年，产品应该还是LLM为底，业务为主体，剩下的人工去解决。

---

# 机器学习常规操作套路

作为小白，想学习/了解/深入机器学习常规操作套路，那么很好，Kaggle公开讨论区有很多大佬公开的自己的脚本，可以在代码实践中熟悉这些处理步骤，常规线路一般是：
1. 数据清洗
2. 特征挖掘/特征工程
3. 搭建模型
4. 训练模型
5. 给出预测
6. 提交结果

---

# NLP的发展

首先是用神经网络对文本序列的生成建模，例如RNN，基础的RNN其实是输入一个词。假设你输入的种子词是“春天”：
1. 输入词向量（“春天”）到模型。
2. 模型输出一个词的概率分布，可能选择“来了”。
3. 将“来了”作为下一个输入，再次输入模型。
4. 模型继续输出下一个词，例如“，”，然后重复此过程，直到生成完整的句子。
在此之上可能有多个种子词。

## word2vec
- **word2vec** 是无监督学习，不需要标注。有监督学习还是很强的限制条件，必须要有标签标注。
- 预训练语言模型，都是为了获得embedding，提取特征用的。
- 神经语言模型专注于学习任务无关的语义表征，旨在减少人类特征工程的工作量，可以大范围扩展语言模型可应用的任务。进一步，预训练语言模型加强了语义表征的上下文感知能力，并且可以通过下游任务进行微调，能够有效提升下游任务（主要局限于自然语言处理任务）的性能。

---

## Transformer
- 基础目标仅仅是机器翻译，训练目标也是翻译得准，大量文本无监督拿来训练。

## BERT
**BERT（Bidirectional Encoder Representations from Transformers）** 从随机初始化开始的训练目标主要有两个：
- **掩蔽语言模型（Masked Language Model, MLM）**：在输入句子中随机掩蔽一些单词，模型需要预测被掩蔽的单词。
- **下一个句子预测（Next Sentence Prediction, NSP）**：给定一对句子，模型需要判断第二个句子是否是第一个句子的下一个句子。

### 训练集数据的例子
- **例子 1（MLM）**：
  - 输入：The cat sat on the [MASK].
  - 目标：mat
  - 整个上下文：The cat sat on the mat.
- **例子 2（MLM）**：
  - 输入：Artificial [MASK] is fascinating.
  - 目标：intelligence
  - 整个上下文：Artificial intelligence is fascinating.
- **例子 3（NSP）**：
  - 输入句子对：
    - 句子 1：The sky is blue.
    - 句子 2：It is a beautiful day.
  - 目标：否（这两个句子没有直接关系）
- **例子 4（NSP）**：
  - 输入句子对：
    - 句子 1：The cat is sleeping.
    - 句子 2：It is dreaming.
  - 目标：是（这两个句子有逻辑上的连续性）

## GPT-1
- 与 BERT 模型不同的是，GPT-1 采用了仅有解码器的 Transformer 架构，以及基于下一个词元预测的预训练任务进行模型的训练。

### 例子：
- **例子 1**：
  - 输入：The quick brown fox
  - 目标：jumps
  - 整个上下文：The quick brown fox jumps
- **例子 2**：
  - 输入：In the year 2020, the world faced
  - 目标：a pandemic
  - 整个上下文：In the year 2020, the world faced a pandemic

---

# 第二章：大语言模型的构建过程

大语言模型的构建过程、扩展法则（Scaling Law）、涌现能力（Emergent Abilities），然后将介绍 GPT 系列模型的研发历程。

- 神经网络是一种具有特定模型结构的函数形式，而大语言模型则是一种基于 Transformer 结构的神经网络模型。
- 大语言模型的优化目标更加泛化，不仅仅是为了解决某一种或者某一类特定任务，而是希望能够作为通用任务的求解器。

一般来说，这个训练过程可以分为 **大规模预训练** 和 **指令微调与人类对齐** 两个阶段。

---

## 指令微调（Supervised Fine-Tuning，SFT）

SFT 是一种基于监督学习的微调方法，通常用于提升预训练语言模型在特定任务上的性能。

### SFT 的主要特点和工作流程：
1. **预训练模型**：SFT 通常基于一个已经过大量无监督数据预训练的基础模型，比如 GPT 或 BERT。
2. **有监督标注数据**：使用带有输入输出对的标注数据。
3. **微调训练**：通过监督学习进行训练，调整模型参数以最小化预测输出与真实标签之间的差距。
4. **任务适应性**：经过 SFT 之后，模型能够对目标任务产生更准确和一致的输出，表现为在测试数据上的精度提升。

### 举例说明：
假设我们有一个预训练的语言模型，想微调它以适应情感分析任务：

- **数据**：有一组情感标注数据，例如：
  - 输入：`The movie was fantastic!`
  - 标签：`Positive`
  
- **训练**：模型会使用这些带标签的数据进行训练，调整参数以更好地预测情感标签。
  
- **结果**：微调后，模型在看到类似的文本时能够准确判断情感倾向。

### SFT 的优点：
- **适应性强**：使预训练模型能够高效应用于特定任务。
- **性能提升**：通过标注数据的指导，提高模型在特定任务上的准确率。

---

## 人工对齐
- RLHF、或者其他 SFT 代替强化学习。

---

以下是你所需要的内容整理和补充：

---

## 第五章 模型结构

大部分现代大语言模型（LLM）都基于因果模型（如GPT系列），还有一些基于前缀补全（例如T5）和编码解码结构（如BERT）。因GPT的成功，许多模型仅使用解码器（decoder），这主要是因为其架构能够在大规模文本生成任务中取得较好的效果。

### 相比于RNN、LSTM的进步
- **GPU并行化**：Transformer相比于RNN和LSTM的一大进步是其结构更适合GPU并行计算。RNN和LSTM需要顺序计算每一个时刻的状态，导致计算无法并行，而Transformer的自注意力机制能够同时处理序列中的所有词元，从而大幅度提高计算效率。
- **长文本序列的建模**：Transformer能够捕捉长距离词元之间的关系，克服了RNN和LSTM在处理长序列时可能出现的梯度消失或爆炸问题。
- **多头自注意力**：自注意力机制允许每个词元与序列中的所有其他词元相互作用，能够高效地学习长距离依赖关系，这在RNN和CNN中是难以实现的。

### 位置编码

尽管绝对位置编码能够一定程度上建模位置信息，但它只能局限于建模训练样本中出现的位置，无法建模训练数据中未出现过的位置信息。因此，它极大地限制了模型处理长文本的能力。为了解决这一问题，研究者提出了不同的编码方式，如相对位置编码和更复杂的位置编码方案。我们将在第5.2.4节深入讨论这些不同的位置编码方式。

### 多头自注意力机制

多头自注意力机制是Transformer架构的核心创新技术之一。相比于传统的循环神经网络（RNN）和卷积神经网络（CNN），自注意力机制具有能够直接建模任意距离的词元之间交互关系的优势。

#### 自注意力 vs 循环神经网络（RNN）：
- 在RNN中，信息是通过时间步长逐步传递的，当前时刻的状态依赖于前一时刻的状态。因此，RNN在处理长序列时容易出现梯度爆炸或梯度消失的问题。
- 而在Transformer中，信息在每一层都能直接与序列中的所有其他词元交互。这种并行计算的方式大大增强了模型对长文本的建模能力。

#### 自注意力 vs 卷积神经网络（CNN）：
- 在CNN中，卷积核只能处理局部窗口内的词元，并通过堆叠多层来扩大感受野，最终捕捉长距离依赖关系。每一层卷积只能看到一个小范围的上下文，直到后续的卷积层才可以逐步捕捉更远距离的信息。
- 在Transformer中，自注意力机制能够直接将序列中的所有词元视为同等重要并进行交互，从而能够在一个层次结构内捕捉到全局的信息。

#### 示例：卷积神经网络的堆叠

假设我们有一个句子：“The cat sat on the mat.”，并通过CNN进行处理：

1. **输入层**：将句子转换为词向量表示：
   - `The`: [0.1, 0.2, 0.3]
   - `cat`: [0.4, 0.5, 0.6]
   - `sat`: [0.7, 0.8, 0.9]
   - `on`: [0.1, 0.1, 0.1]
   - `the`: [0.2, 0.2, 0.2]
   - `mat`: [0.3, 0.3, 0.3]

2. **第一层卷积**：使用一个卷积核（如大小为2的窗口）进行卷积操作。该卷积核处理相邻的词元（例如 `(The, cat)`, `(cat, sat)`），并生成一个特征图。

3. **第二层卷积**：将第一层卷积的输出输入到第二层卷积，这一层将能够捕捉更远距离的词元关系（例如通过 `(cat, sat)` 和 `(sat, on)` 组合来捕捉 `cat` 和 `on` 之间的依赖关系）。

4. **更多卷积层的堆叠**：通过堆叠更多卷积层，CNN能够逐层捕捉更远距离词元之间的关系，最终可能将 `cat` 和 `mat` 之间的关系捕捉到。

### Transformer 的 QKV 构想与随机初始化

Transformer架构的自注意力机制基于 **查询（Q）**、**键（K）** 和 **值（V）** 三个向量的计算。每个词元首先通过线性变换生成Q、K、V向量，这些向量经过自注意力机制后，计算出加权的输出。

- **QKV的初始化**：在Transformer中，Q、K、V的初始化是随机的。每个头的参数都是独立初始化的，尽管是随机初始化，但每个头能够从不同的角度理解输入文本的特征。多个头可以并行地关注输入文本的不同部分，从而捕捉不同的上下文信息。
  
### 需要深入了解的部分：层归一化与残差连接

- **层归一化（Layer Normalization）**：是对每一层的输出进行标准化，使得每个神经元的激活值具有相同的均值和方差，进而提升训练的稳定性。它帮助加速收敛并防止梯度爆炸或消失。

- **残差连接（Residual Connection）**：残差连接的思想是将输入直接与输出相加，使得模型在训练时能够避免信息在多层网络中丢失。残差连接帮助缓解深层网络中的梯度消失问题，使得模型更易训练和收敛。

### Decoder的Q与K的关系

在解码器（decoder）中，**查询（Q）** 可以与 **键（K）** 进行比较，这是自注意力机制中关键的计算部分。在Transformer中，**Q** 和 **K** 都是从输入的不同层生成的，它们用于计算注意力权重。由于Q和K都是通过线性变换得到的，因此在解码器中，Q与K之间的关系会直接影响到模型如何根据当前输入和历史上下文来生成下一步的输出。

---

以上是对你问题的整理和补充，希望能帮助你更好地理解Transformer模型的架构和工作原理。如果需要更多信息或进一步讨论某个部分，随时告诉我！


大多数常用的损失函数在训练时都是可导的，或者即使在某些点不可导，优化算法仍然能有效进行。深度学习框架如 TensorFlow 和 PyTorch 内部有处理这些不可导点的机制，如使用次梯度或者通过平滑损失函数来确保训练的顺利进行。

现在常用mini_batch+adam优化，整个epoch要几天更新一次不现实，随机梯度下降噪声