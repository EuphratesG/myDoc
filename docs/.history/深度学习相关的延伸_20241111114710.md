# 深度学习相关的延伸


## gbdt是什么
Gradient Boosting Decision Tree，梯度提升决策树  
属于提升算法（Boosting）的一种。它通过逐步构建多个决策树，并结合每个树的预测结果来提高模型的准确性。GBDT的核心思想是通过优化目标函数（通常是损失函数）来减少误差，并在每一步迭代中使用梯度下降来修正前一轮预测的残差。

## moe
研究低算力slm 产生的灵感，我或许不需要那么多领域的覆盖，所以研究混合专家，做有限领域垂直应用。就好比人类社会，各有分工，简洁明了。  
同时直观想法横向拓展参数量，理论上就应该有提升。  
如何提升MOE并行的效率，专家之间的网络通信会成为计算的瓶颈。而且GPU擅长做矩阵运算，不擅长做分支；每个专家小模型分配的样本数较少，无法得到充分的训练；（是否可以先训练出若干个完整的大模型，例如数学大模型、代码大模型、问答大模型等，然后作为专家的初始化？）需要确保专家模型上的负载均衡

其实就是把attention的ffn换成多个网络（可以是ffn，也可以是别的所有）  
训练和推理的时候在前面加一个gate（router，也是ffn），同时设定超参数topk决定有几个专家加入推理。  
